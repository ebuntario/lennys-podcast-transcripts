---
type: insight
title: The "bitter lesson" of scaling simple models with data
concepts:
  - "[[concepts/ai-scaling]]"
  - "[[concepts/machine-learning]]"
  - "[[concepts/algorithmic-development]]"
source_guest: Dr. Fei-Fei Li
source_episode: The Godmother of AI on jobs, robots & why world models are next | Dr. Fei-Fei Li
source: "[[guests/dr-fei-fei-li|Dr. Fei Fei Li]]"
---
Historical analysis of AI progress reveals that simpler models trained on vast amounts of data consistently outperform more complex models with less data. This principle underscores the importance of [[concepts/data-strategy|data scale]] over intricate [[concepts/algorithmic-development|algorithmic design]] for many tasks. However, this approach faces unique challenges in domains like robotics where action-oriented 3D data is scarce.