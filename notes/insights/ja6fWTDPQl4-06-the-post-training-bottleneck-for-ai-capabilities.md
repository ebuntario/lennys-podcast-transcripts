---
type: insight
title: The Post-Training Bottleneck for AI Capabilities
concepts:
  - "model-training"
  - "ai-evals"
  - "reinforcement-learning"
source_guest: Brendan Foody
source_episode: Why experts writing AI evals is creating the fastest-growing companies in history | Brendan Foody
source: "[[guests/brendan-foody|Brendan Foody]]"
---
The primary bottleneck for AI labs is no longer pre-training data but post-training: how to measure and reward specific model capabilities. This requires experts to create [[concepts/ai-evals|evals]] and rubrics that define "good" outputs, which then serve as verifiers in a [[concepts/reinforcement-learning|reinforcement learning]] environment. This expert-driven, data-efficient approach is replacing older methods like supervised fine-tuning.