---
type: insight
title: Keep LLM judge evaluations binary and specific
concepts:
  - "ai-evals"
  - "llm-applications"
  - "measurement"
source_guest: Hamel Husain
source_episode: Why AI evals are the hottest new skill for product builders | Hamel Husain & Shreya Shankar
source: "[[guests/hamel-husain-and-shreya-shankar|Hamel Husain & Shreya Shankar]]"
---
When creating an LLM-as-a-judge evaluator, scope it to a single, specific failure mode and require a binary pass/fail output. Avoid Likert scales (e.g., 1-5 ratings) because they obscure decision-making and make metrics hard to interpret. A tightly scoped, binary judge is more reliable and actionable for improving your product.