---
type: insight
title: Indirect prompt injection via external data is a major unsolved threat
concepts:
  - "prompt-injection"
  - "agentic-ai"
source_guest: "Sander Schulhoff"
source_episode: "Why securing AI is harder than anyone expected and guardrails are failing | HackAPrompt CEO"
source: "[[guests/sander-schulhoff-20|Sander Schulhoff 2.0]]"
---
A severe vulnerability occurs when an AI agent reads external data (like emails or webpages) that contains hidden malicious instructions. This "indirect" [[concepts/prompt-injection|prompt injection]] is harder to defend against than direct user prompts, as the agent must sometimes act on external data, making it difficult to distinguish legitimate from malicious instructions.