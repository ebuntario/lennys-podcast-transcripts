---
type: insight
title: Reinforcement learning uses comparison-based feedback for training
concepts:
  - "reinforcement-learning"
  - "model-training"
  - "human-feedback"
source_guest: Chip Huyen
source_episode: AI Engineering 101 with Chip Huyen (Nvidia, Stanford, Netflix)
source: "[[guests/chip-huyen|Chip Huyen]]"
---
[[concepts/reinforcement-learning|Reinforcement Learning from Human Feedback (RLHF)]] often uses comparison-based signals because humans find it easier to judge which of two responses is better rather than assigning an absolute score. This feedback trains a reward model that then guides the main model to produce higher-quality outputs.