---
type: insight
title: Simple chatbots pose limited risk, but agentic systems are dangerous
concepts:
  - "agentic-ai"
  - "ai-security"
  - "permissioning"
source_guest: "Sander Schulhoff"
source_episode: "Why securing AI is harder than anyone expected and guardrails are failing | HackAPrompt CEO"
source: "[[guests/sander-schulhoff-20|Sander Schulhoff 2.0]]"
---
If an AI system is a read-only chatbot with no ability to take actions or access sensitive data, the security risk is primarily reputational. The real danger begins with [[concepts/agentic-ai|agentic AI]] that can perform actions (send emails, modify databases) or access privileged data, as any permission granted can be exploited by an attacker.