---
type: insight
title: The trajectory of AI actions matters as much as the final outcome
concepts:
  - "[[concepts/reinforcement-learning]]"
  - "[[concepts/ai-training]]"
  - "[[concepts/efficiency-optimization]]"
source_guest: Edwin Chen
source_episode: The $1B Al company training ChatGPT, Claude & Gemini on the path to responsible AGI | Edwin Chen
source: "[[guests/edwin-chen|Edwin Chen]]"
---
In [[concepts/reinforcement-learning|reinforcement learning]], it's crucial to evaluate the entire trajectory of a model's actions, not just the final result. A model might reach a correct answer through inefficient, roundabout methods or by reward-hacking. Training must reinforce not just correctness but also efficient, logical, and reflective problem-solving paths to build robust and useful agents.