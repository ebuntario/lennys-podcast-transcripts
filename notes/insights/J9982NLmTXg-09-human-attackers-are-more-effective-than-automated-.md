---
type: insight
title: Human attackers are more effective than automated red-teaming systems
concepts:
  - "ai-red-teaming"
  - "adversarial-robustness"
source_guest: "Sander Schulhoff"
source_episode: "Why securing AI is harder than anyone expected and guardrails are failing | HackAPrompt CEO"
source: "[[guests/sander-schulhoff-20|Sander Schulhoff 2.0]]"
---
Research shows that human [[concepts/ai-red-teaming|AI red teaming]] breaks state-of-the-art AI defenses in 10-30 attempts, while automated systems require orders of magnitude more attempts and are less successful. This demonstrates that adaptive, creative human reasoning remains superior to automated attacks for finding novel vulnerabilities.