---
type: insight
title: Use evals for online monitoring, not just pre-ship tests
concepts:
  - "monitoring"
  - "ai-evaluation"
  - "product-analytics"
source_guest: Shreya Shankar
source_episode: Why AI evals are the hottest new skill for product builders | Hamel Husain & Shreya Shankar
source: "[[guests/hamel-husain-and-shreya-shankar|Hamel Husain & Shreya Shankar]]"
---
LLM judges and automated evaluators are powerful for continuous monitoring, not just unit tests. You can sample production traces daily, run your evaluators, and create dashboards to track specific failure rates over time. This turns [[concepts/ai-evaluation|evals]] into a live feedback loop for product quality.