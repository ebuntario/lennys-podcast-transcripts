Transcript → Obsidian Knowledge Agent
Implementation Plan

Purpose

Convert 300+ podcast transcripts into atomic, linkable Obsidian notes automatically using an AMP skill and OpenRouter.

The system transforms long transcripts into small reusable ideas so Obsidian can function as a true knowledge graph rather than a document folder.

End result:

Raw transcripts → thousands of atomic insight notes → searchable and cross-linked knowledge base.

⸻

System Principles (design constraints)

These rules keep the system sane and prevent entropy.

Sources are immutable
Never modify files inside episodes/.

Derived notes are generated artifacts
Everything created by AI goes into notes/.

Deterministic structure
Code decides filenames, folders, and metadata. AI only writes content.

Idempotent execution
Running the agent multiple times must not duplicate notes.

Atomic notes
One idea per file. Small beats comprehensive.

Low creativity
Use low temperature. Consistency matters more than style.

If any of these are broken, the system becomes messy fast.

⸻

High-Level Architecture

Conceptually this is a tiny ETL pipeline:

Scanner → Parser → LLM via OpenRouter (idea extraction) → Note writer → Obsidian

More concretely:

episodes/transcript.md
→ parse metadata
→ send transcript text to OpenRouter
→ receive atomic notes
→ save notes/insights/*.md

The LLM is only responsible for extracting ideas.
Everything else is deterministic code.

⸻

Repository Structure

Create this layout:

episodes/            (raw, read-only)
notes/
insights/          (atomic notes generated by agent)
summaries/         (optional later)
.processed/        (marker files for idempotency)
scripts/             (agent code)
skills/              (AMP skill configs)

Keep sources and generated content strictly separate.

⸻

Phase 1 — Environment Setup

Install dependencies:

Node:
openai (OpenRouter uses OpenAI-compatible API)
gray-matter
slugify

Set API key:

OPENROUTER_API_KEY=your_key

Verify:
You can run a simple OpenRouter API call locally.

Success criteria:
OpenRouter call works from terminal.

⸻

Phase 2 — Build the Transcript Agent Script

Create:

scripts/transcript-agent.ts

Responsibilities:
	1.	Walk through episodes/**/transcript.md
	2.	Parse YAML frontmatter
	3.	Extract:
	•	title
	•	video_id
	•	keywords
	4.	Send only transcript body to OpenRouter
	5.	Receive atomic notes
	6.	Split on ===NOTE===
	7.	Save each note as its own .md file
	8.	Mark episode as processed

Important:
Never send the YAML or file headers to the LLM. Only the transcript text.

Success criteria:
Processing one transcript produces 10–25 clean atomic notes.

⸻

Phase 3 — LLM Prompt Design

The LLM must extract reusable knowledge, not summaries.

Recommended model via OpenRouter:
anthropic/claude-sonnet-4-20250514 (or similar reasoning model)

Behavior requirements:

Ignore banter
Ignore timestamps
Extract principles and insights
One idea per note
2–5 sentences per note
Standalone meaning

Strict output format:

Title
Frontmatter
Content
===NOTE=== separator

Low temperature (around 0.2)

If you see paragraphs or summaries, the prompt is wrong.

Success criteria:
Output looks like Lego bricks, not essays.

⸻

Phase 4 — Idempotency and Safety

Prevent duplicate generation.

For each episode:

Create:
notes/.processed/{video_id}.done

Before processing:
If marker exists → skip

This guarantees:
Re-running the agent does nothing unless new transcripts exist.

Success criteria:
Second run processes zero files.

⸻

Phase 5 — Wrap as AMP Skill

Create:

skills/transcript-to-obsidian.yaml

This simply runs the script:

Run → node scripts/transcript-agent.ts

AMP becomes a convenient task runner.

Execution:

amp run transcript-to-obsidian

Success criteria:
Single command runs the whole pipeline.

⸻

Phase 6 — Testing Strategy

Test in small batches.

Run:
1 transcript → inspect
5 transcripts → inspect
20 transcripts → inspect

Look for:
bad filenames
duplicate ideas
broken markdown
inconsistent tags

Fix issues before full run.

Success criteria:
Notes look consistent and usable in Obsidian.

⸻

Phase 7 — Full Run

Execute:

amp run transcript-to-obsidian

Expected results:

300 transcripts
→ ~4,000–7,000 notes

Runtime depends on API speed.

After completion:

notes/insights populated
.processed filled
no crashes

Open Obsidian Graph view and verify connections appear.

This is the “second brain” moment.

⸻

Phase 8 — Obsidian Enablement (Optional)

Install Dataview plugin.

Create dashboards to query notes.

Example use cases:

All insights about growth
All notes from a specific guest
All leadership-related ideas

This turns markdown into a queryable knowledge base.

⸻

Operational Workflow

Normal usage becomes:

Add new transcript to episodes/
Run:
amp run transcript-to-obsidian

Agent processes only new files automatically.

No manual steps.

⸻

Future Enhancements (optional)

Only after the core system is stable.

Possible additions:

Episode summaries
Parallel processing
Automatic Maps of Content
Duplicate detection
Cross-link suggestions
Embedding search

These are optimizations, not requirements.

Ship the boring version first.

⸻

Definition of Done

The system is complete when:

One command processes all transcripts
Notes are atomic and readable
No manual editing required
Re-running does not duplicate files
Obsidian graph shows dense connections

At this point you’ve effectively built a personal research database powered by language models.

Not a notes app.
More like a tiny semantic compiler for human ideas.

Which is a wonderfully nerdy thing to own.